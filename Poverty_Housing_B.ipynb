{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from census import Census\n",
    "from api_keys import api_key\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from unidecode import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Years to loop through \n",
    "years = [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2021, 2022, 2023]  # You can add more years here\n",
    "dsource = 'acs'\n",
    "dname = 'acs1'\n",
    "# Data columns to fetch\n",
    "cols = 'NAME,B25077_001E,B25058_001E,B15003_022E,B01003_001E,B23025_004E,B17001_002E,B23025_003E'  \n",
    "# List of all state FIPS codes\n",
    "\n",
    "state_fips_codes = ['01', '02', '04', '05', '06', '08', '09', '10', '11', '12', '13', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29',\n",
    "    '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '44', '45', '46', '47', '48', '49', '50', '51', '53', '54', '55', '56']  \n",
    "\n",
    "# Initialize an empty DataFrame to collect data\n",
    "all_data = []\n",
    "\n",
    "# Loop through each year\n",
    "for year in years:\n",
    "    \n",
    "    # Loop through all states to fetch data for all counties\n",
    "    for state in state_fips_codes:\n",
    "        # Construct the data URL for querying each state and its counties for the current year\n",
    "        data_url = f'https://api.census.gov/data/{year}/{dsource}/{dname}?get={cols}&for=county:*&in=state:{state}'\n",
    "\n",
    "        # Send the GET request to the Census API\n",
    "        response = requests.get(data_url)\n",
    "\n",
    "        # Check if the request was successful (200 indicates request was successfully processed)\n",
    "        if response.status_code == 200:\n",
    "            # Parse the response JSON data\n",
    "            data = response.json()\n",
    "            \n",
    "            # Create a DataFrame from the response data\n",
    "            df = pd.DataFrame(data[1:], columns=data[0])  # Skip the header row\n",
    "            \n",
    "            # Rename columns\n",
    "            df = df.rename(columns={\n",
    "                'NAME': 'County Name',\n",
    "                'state': 'State FIPS',\n",
    "                'county': 'County FIPS',\n",
    "                'B25077_001E': 'Median House Price ($)',\n",
    "                'B25058_001E': 'Median Rent ($)',\n",
    "                'B01003_001E': 'Total Population',\n",
    "                'B15003_022E': 'Population with Bachelor\\'s Degree',\n",
    "                'B23025_004E': 'Number of Employed People',\n",
    "                'B17001_002E': 'People with Income Below Poverty',\n",
    "                'B23025_003E': 'Total Labor Force'\n",
    "            })\n",
    "            \n",
    "            # Add a column for the year\n",
    "            df['Year'] = year\n",
    "            \n",
    "            # # Split the 'County Name' column into 'County' and 'State'\n",
    "            # df[['County', 'State']] = df['County Name'].str.split(',', expand=True)\n",
    "            \n",
    "            # # Optionally, clean up any leading/trailing spaces from the new columns\n",
    "            # df['County'] = df['County'].str.strip()\n",
    "            # df['State'] = df['State'].str.strip()\n",
    "            \n",
    "            # # Drop the original 'County Name' column\n",
    "            # df = df.drop(columns=['County Name'])\n",
    "            \n",
    "            # Append the data for this year and state to the list\n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} for State: {state} in Year: {year}\")\n",
    "\n",
    "# Concatenate all data into a single DataFrame\n",
    "clean_data_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the resulting DataFrame to a CSV file\n",
    "clean_data_df.to_csv('census_data_all_year.csv', index=False)\n",
    "\n",
    "print(\"Data saved to 'census_data_all_year.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert columns to numeric, errors='coerce' will turn invalid values into NaN\n",
    "numeric_columns = [\n",
    "    'Median House Price ($)', 'Median Rent ($)', 'Total Population',\n",
    "    'Population with Bachelor\\'s Degree', 'Number of Employed People',\n",
    "    'People with Income Below Poverty', 'Total Labor Force'\n",
    "]\n",
    "\n",
    "# Convert all columns to numeric\n",
    "for col in numeric_columns:\n",
    "    clean_data_df[col] = pd.to_numeric(clean_data_df[col], errors='coerce')\n",
    "\n",
    "# Now print the min and max values, ignoring NaNs\n",
    "print('Minimum Values:')\n",
    "print(clean_data_df.min())\n",
    "print('---------------------------------------------------')\n",
    "print('Maximum Values:')\n",
    "print(clean_data_df.max())\n",
    "\n",
    "final_df = clean_data_df.dropna()\n",
    "\n",
    "# Optionally, if you want to handle NaNs by filling them with a specific value:\n",
    "#clean_data_df.fillna(0, inplace=True)  # Fill NaN values with 0\n",
    "\n",
    "# Check for missing values and data types\n",
    "print('Number of Null Values in Each Column:')\n",
    "print(clean_data_df.isnull().sum())\n",
    "\n",
    "# Removes Non-ASCII Characters\n",
    "clean_data_df['County Name Cleaned'] = df['County Name'].apply(lambda x: unidecode(x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_df.to_csv('census_data_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_df['Annual Rent-to-Price Ratio'] = ((clean_data_df['Median Rent ($)']*12) / clean_data_df ['Median House Price ($)']) * 100\n",
    "clean_data_df['Employment Rate %'] = (clean_data_df['Number of Employed People'] / clean_data_df['Total Labor Force']) * 100\n",
    "clean_data_df['% People Living in Poverty'] = (clean_data_df['People with Income Below Poverty'] / clean_data_df['Total Population']) * 100\n",
    "\n",
    "clean_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GROUPING ALL DATA BY COUNTIES\n",
    "#To ensure exact matches, we need to group by all State FIPS, County FIPS, and County Name.\n",
    "#This is because counties in different states may have the same name.\n",
    "clean_data_df['Combined FIPS'] = clean_data_df['County FIPS'] + clean_data_df['State FIPS']\n",
    "\n",
    "grouped_df = clean_data_df.groupby(['County Name', 'Combined FIPS'])\n",
    "grouped_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
